import os
import streamlit as st
from langchain.document_loaders import PyPDFLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI
from langchain.chains import ConversationalRetrievalChain

# Streamlit Page Setup
st.set_page_config(page_title="AI Knowledge Assistant", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– AI Knowledge Assistant")
st.markdown("Upload your documents (PDF or TXT) and ask any question related to them.")

# Input API Key
api_key = st.text_input("ğŸ”‘ Enter your OpenAI API Key:", type="password")
if not api_key:
    st.warning("Please enter your OpenAI API key to continue.")
    st.stop()
os.environ["OPENAI_API_KEY"] = api_key

# Upload files
uploaded_files = st.file_uploader("ğŸ“‚ Upload Files", type=["pdf", "txt"], accept_multiple_files=True)
build_btn = st.button("âš™ï¸ Build Knowledge Base")

if build_btn and uploaded_files:
    with st.spinner("Processing files..."):
        docs = []
        for file in uploaded_files:
            if file.name.endswith(".pdf"):
                loader = PyPDFLoader(file)
            else:
                loader = TextLoader(file)
            docs.extend(loader.load())

        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
        chunks = splitter.split_documents(docs)
        embeddings = OpenAIEmbeddings()
        vectordb = FAISS.from_documents(chunks, embeddings)
        st.session_state["db"] = vectordb
        st.success("âœ… Knowledge Base Ready!")

if "db" in st.session_state:
    vectordb = st.session_state["db"]
    chat_history = st.session_state.get("chat_history", [])

    query = st.text_input("ğŸ’¬ Ask your question:")
    if st.button("Ask"):
        qa_chain = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.1), vectordb.as_retriever())
        result = qa_chain({"question": query, "chat_history": chat_history})
        answer = result["answer"]
        chat_history.append((query, answer))
        st.session_state["chat_history"] = chat_history

    if "chat_history" in st.session_state:
        for q, a in st.session_state["chat_history"]:
            st.markdown(f"**ğŸ§  You:** {q}")
            st.markdown(f"**ğŸ¤– AI:** {a}")
